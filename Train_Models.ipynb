{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_Models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJBkC7nXoN8n"
      },
      "source": [
        "# Reference:\n",
        "#### https://github.com/PerpetualSmile/Sentiment-Analylsis-based-on-Attention-Mechanism/blob/master/Train%20Models.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQuqiVP30CnJ"
      },
      "source": [
        "## **IMPORTANT**: Create folders and upload files based on the following structure:\n",
        "\n",
        "*   Transformer.py\n",
        "*   utils.py\n",
        "*   dataset\n",
        "  *   IMDB\n",
        "      *   X_train.h5 \n",
        "      *   y_train.h5\n",
        "      *   X_val.h5\n",
        "      *   y_val.h5\n",
        "      *   X_test.h5\n",
        "      *   y_test.h5\n",
        "      *   word2num_series.h5\n",
        "      *   test.csv\n",
        "  *   Yelp\n",
        "      *   X_train.h5\n",
        "      *   y_train.h5\n",
        "      *   X_val.h5\n",
        "      *   y_val.h5\n",
        "      *   X_test.h5\n",
        "      *   y_test.h5\n",
        "      *   word2num_series.h5\n",
        "      *   yelp_test.csv\n",
        "*   word2vector\n",
        "  *   glove.twitter.27B.200d.txt\n",
        "*   output\n",
        "  *   model_save\n",
        "      *   Transformer_on_IMDB_l1_h1.pth\n",
        "      *   Transformer_on_IMDB_l1_h2.pth\n",
        "      *   Transformer_on_IMDB_l1_h4.pth\n",
        "      *   Transformer_on_IMDB_l1_h8.pth\n",
        "      *   Transformer_on_IMDB_l2_h1.pth\n",
        "      *   Transformer_on_IMDB_l2_h2.pth\n",
        "      *   Transformer_on_IMDB_l2_h4.pth\n",
        "      *   Transformer_on_IMDB_l2_h8.pth\n",
        "      *   Transformer_on_IMDB_l3_h1.pth\n",
        "      *   Transformer_on_IMDB_l3_h2.pth\n",
        "      *   Transformer_on_IMDB_l3_h4.pth\n",
        "      *   Transformer_on_IMDB_l3_h8.pth\n",
        "      *   Transformer_on_Yelp_l1_h1.pth\n",
        "      *   Transformer_on_Yelp_l1_h2.pth\n",
        "      *   Transformer_on_Yelp_l1_h4.pth\n",
        "      *   Transformer_on_Yelp_l1_h8.pth\n",
        "      *   Transformer_on_Yelp_l2_h1.pth\n",
        "      *   Transformer_on_Yelp_l2_h2.pth\n",
        "      *   Transformer_on_Yelp_l2_h4.pth\n",
        "      *   Transformer_on_Yelp_l2_h8.pth\n",
        "      *   Transformer_on_Yelp_l3_h1.pth\n",
        "      *   Transformer_on_Yelp_l3_h2.pth\n",
        "      *   Transformer_on_Yelp_l3_h4.pth\n",
        "      *   Transformer_on_Yelp_l3_h8.pth\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "SqhhypPdj-Yw",
        "outputId": "2dc5167f-7b75-4a58-e4d5-d6103e5eea9a"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pack_sequence, pad_packed_sequence, pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset, SequentialSampler\n",
        "\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "import copy\n",
        "import warnings\n",
        "import jieba\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from matplotlib.collections import PatchCollection\n",
        "from tqdm import tqdm\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from utils import pad_and_sort_batch, preprocess_for_batch, pad_or_truncate, clean_text, clean_text_zh, transform_punc\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.7.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmQhLoTxk3ZG"
      },
      "source": [
        "# set random seeds to keep the results identical\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    \n",
        "def worker_init_fn(worker_id):\n",
        "    setup_seed(torch.initial_seed() + worker_id)\n",
        "    \n",
        "GLOBAL_SEED = 2019\n",
        "setup_seed(GLOBAL_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OAOdwUok8ou"
      },
      "source": [
        "base_dir = 'output/'\n",
        "MODEL_NAME = 'Transformer-on-Yelp-l3-h1'\n",
        "NO_OF_LAYERS = 3\n",
        "NO_OF_HEADS = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgTEKby0lGSQ"
      },
      "source": [
        "### For mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX5dqNDFk_ke"
      },
      "source": [
        "# base_dir = './'\n",
        "# # setting in google colab\n",
        "# root_dir = \"/content/gdrive/My Drive/\"\n",
        "# base_dir = root_dir + 'Colab Notebooks/'\n",
        "# # pre setting in google colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive', force_remount=True)\n",
        "# !pip install -U pandas\n",
        "# import nltk\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('wordnet')\n",
        "# import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN8rxZ-3lJar"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF0OLaoKlJB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a9ccb2-4d15-4757-b96b-5ed16a518b43"
      },
      "source": [
        "# data_pth = 'dataset/IMDB/'  #For IMDB\n",
        "data_path = 'dataset/Yelp/'   #For Yelp\n",
        "\n",
        "!pip install --upgrade tables"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tables in /usr/local/lib/python3.6/dist-packages (3.6.1)\n",
            "Requirement already satisfied, skipping upgrade: numexpr>=2.6.2 in /usr/local/lib/python3.6/dist-packages (from tables) (2.7.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from tables) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsNgSjZYlYIJ"
      },
      "source": [
        "X_train = pd.read_hdf(data_path+'X_train.h5', key='s')\n",
        "y_train = pd.read_hdf(data_path+'y_train.h5', key='s')\n",
        "\n",
        "X_val = pd.read_hdf(data_path+'X_val.h5', key='s')\n",
        "y_val = pd.read_hdf(data_path+'y_val.h5', key='s')\n",
        "\n",
        "word2num_series = pd.read_hdf(data_path+'word2num_series.h5', key='s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prSPqst7lahv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75c100b0-192f-4be9-8155-a1ad29ba5ec8"
      },
      "source": [
        "print(len(X_train), len(X_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "447999 112000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Blb5xCtlg2F"
      },
      "source": [
        "# Load pretrained word embedding matrix (Glove)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfK4Wnialhj_"
      },
      "source": [
        "pre_embedding = {}\n",
        "with open('word2vector/glove.twitter.27B.200d.txt', encoding='utf8') as f:\n",
        "    for line in f.readlines():\n",
        "        tmp = line.strip().split()\n",
        "        if tmp[0] in word2num_series:\n",
        "            pre_embedding[tmp[0]] = np.array(tmp[1:]).astype(np.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGwXAP5Pll7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23017a06-47ec-4433-d75f-833e83155ad3"
      },
      "source": [
        "vocab_size = len(word2num_series)+3\n",
        "print('vocab_size', vocab_size)\n",
        "\n",
        "dim = pre_embedding['movie'].shape[0]\n",
        "print('dimension:', dim)\n",
        "\n",
        "mean = np.mean([value for _, value in pre_embedding.items()])\n",
        "std = np.std([value for _, value in pre_embedding.items()])\n",
        "print('mean:', np.mean([value for _, value in pre_embedding.items()]))\n",
        "print('std:', np.std([value for _, value in pre_embedding.items()]))\n",
        "print('max:', np.max([value for _, value in pre_embedding.items()]))\n",
        "print('min:', np.min([value for _, value in pre_embedding.items()]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab_size 20000\n",
            "dimension: 200\n",
            "mean: 0.002889593144016764\n",
            "std: 0.4403811050924952\n",
            "max: 2.6397\n",
            "min: -6.7986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yda5kyXHlqDq"
      },
      "source": [
        "embedding_matrix = np.random.randn(vocab_size, dim)*std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5qbisaxlsOb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cecbc3dd-aef2-4ac0-85e8-ae5f4aed50a3"
      },
      "source": [
        "miss_word = 0\n",
        "for word, idx in word2num_series.items():\n",
        "    try:\n",
        "        embedding_matrix[idx] = pre_embedding[word]\n",
        "    except:\n",
        "        miss_word += 1\n",
        "miss_word"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1614"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIn4FDNAlxIH"
      },
      "source": [
        "np.testing.assert_array_almost_equal(embedding_matrix[word2num_series['movie']], pre_embedding['movie'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "730AFDmzl1gG"
      },
      "source": [
        "# Build pytorch dataset and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6rQa_OWmAhn"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if self.features[idx].size(0) > 0:\n",
        "            features = self.features[idx]\n",
        "        else:\n",
        "            features = torch.LongTensor([1])\n",
        "        return features, self.labels[idx], max(len(self.features[idx]), 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P9wYdDtmGz3"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "# ignore last batch if smaller than batch_size\n",
        "X_train_sorted_tensors, y_train_sorted_tensors = preprocess_for_batch(X_train, y_train, BATCH_SIZE) \n",
        "X_valid_tensors = [torch.tensor(x, dtype=torch.int64) for x in X_val]\n",
        "y_valid_tensors = [torch.tensor(y, dtype=torch.int64) for y in y_val]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iG4UMtV-tNZ"
      },
      "source": [
        "#### IMPORTANT: Just for Transformer model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2olMaDgmJfB"
      },
      "source": [
        "# truncate long sentence's length to maxlen instead of padding to save memory\n",
        "MAXLEN = 500 \n",
        "X_train_sorted_tensors = [pad_or_truncate(x, maxlen=MAXLEN, pad=False) for x in X_train_sorted_tensors]\n",
        "X_valid_tensors = [pad_or_truncate(x, maxlen=MAXLEN, pad=False) for x in X_valid_tensors]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTrDSnZK-4aA"
      },
      "source": [
        "# Train and validation data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dALCou1bmLtO"
      },
      "source": [
        "train_dataset = CustomDataset(X_train_sorted_tensors, y_train_sorted_tensors)\n",
        "val_dataset = CustomDataset(X_valid_tensors, y_valid_tensors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_fz4gCEmNxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f50dfbb-b103-4dcc-f4eb-33c9d45670b7"
      },
      "source": [
        "print(\"train-set size:\", len(train_dataset))\n",
        "print(\"valid-set size:\", len(val_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train-set size: 447872\n",
            "valid-set size: 112000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGpM8Ty5mQlM"
      },
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=SequentialSampler(train_dataset), shuffle=False, collate_fn=pad_and_sort_batch, worker_init_fn=worker_init_fn)\n",
        "valid_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=pad_and_sort_batch, worker_init_fn=worker_init_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzafZSssmWKg"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x5UqLHimWkL"
      },
      "source": [
        "from Transformer import Transformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paVCs4Ivmh9Y"
      },
      "source": [
        "# Transformer parameters\n",
        "parameters = {\n",
        "    'n_layers': NO_OF_LAYERS, \n",
        "    'd_model': 200, \n",
        "    'd_ff':512, \n",
        "    'n_heads': NO_OF_HEADS,\n",
        "    'd_k': 60, \n",
        "    'd_v': 60, \n",
        "    'final_att_method': 'concat',\n",
        "    'embedding': embedding_matrix,\n",
        "    'embedding_dropout': 0.5,\n",
        "    'multihead_dropout': 0.2, \n",
        "    'att_dropout': 0.2, \n",
        "    'feedforward_dropout': 0.2, \n",
        "    'final_dropout': 0.1 \n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNEvsrDmml0L"
      },
      "source": [
        "#define transformer architecture and load the model\n",
        "architecture = (parameters['n_layers'], parameters['d_model'], parameters['d_ff'], parameters['n_heads'], parameters['d_k'], parameters['d_v'])\n",
        "model = Transformer(output_size=1, architecture=architecture, embedding=parameters['embedding'], method=parameters['final_att_method'], maxpos=MAXLEN, embedding_dropout=parameters['embedding_dropout'], multihead_dropout=parameters['multihead_dropout'], att_dropout=parameters['att_dropout'], feedforward_dropout=parameters['feedforward_dropout'], final_dropout=parameters['final_dropout'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQZwsQiNm8Fv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb784148-685f-41e7-cc26-5dc2baa41338"
      },
      "source": [
        "model.to(DEVICE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (pos_add_word_embedding): PE_add_Embedding(\n",
              "    (word_embedding): Embedding(20000, 200)\n",
              "    (pos_embedding): Embedding(501, 200)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (encode_layers): ModuleList(\n",
              "    (0): EncoderLayer(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (linear_Q): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (linear_K): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (linear_V): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (attn): ScaleDotProductAttention(\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (out_linear): Linear(in_features=60, out_features=200, bias=True)\n",
              "        (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (postion_feedforward): PoswiseFeedForward(\n",
              "        (conv1): Conv1d(200, 512, kernel_size=(1,), stride=(1,))\n",
              "        (conv2): Conv1d(512, 200, kernel_size=(1,), stride=(1,))\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (1): EncoderLayer(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (linear_Q): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (linear_K): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (linear_V): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (attn): ScaleDotProductAttention(\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (out_linear): Linear(in_features=60, out_features=200, bias=True)\n",
              "        (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (postion_feedforward): PoswiseFeedForward(\n",
              "        (conv1): Conv1d(200, 512, kernel_size=(1,), stride=(1,))\n",
              "        (conv2): Conv1d(512, 200, kernel_size=(1,), stride=(1,))\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (2): EncoderLayer(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (linear_Q): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (linear_K): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (linear_V): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (attn): ScaleDotProductAttention(\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (out_linear): Linear(in_features=60, out_features=200, bias=True)\n",
              "        (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (postion_feedforward): PoswiseFeedForward(\n",
              "        (conv1): Conv1d(200, 512, kernel_size=(1,), stride=(1,))\n",
              "        (conv2): Conv1d(512, 200, kernel_size=(1,), stride=(1,))\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inter_attn): InterAttention(\n",
              "    (linear): Linear(in_features=400, out_features=200, bias=True)\n",
              "    (v): Linear(in_features=200, out_features=1, bias=True)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc): Linear(in_features=200, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0VPNw14m_CJ"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "# ADAM optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTrSQ1sFnFwb"
      },
      "source": [
        "def validate(model, criterion, history):\n",
        "    model.eval()\n",
        "    global best_acc, best_model, validate_history\n",
        "    costs = []\n",
        "    accs = []\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(valid_dataloader):\n",
        "            input_batch, labels, lengths = batch\n",
        "            labels = labels.float().unsqueeze(1) # polarity\n",
        "\n",
        "            # output = model(input_batch, lengths) # RNN\n",
        "            output = model(input_batch)  # Transformer\n",
        "\n",
        "            loss = criterion(output, labels)\n",
        "            costs.append(loss.item())\n",
        "            # polarity\n",
        "            accs.append((output>0).eq(labels>0).float().mean().item())\n",
        "            torch.cuda.empty_cache()\n",
        "    mean_accs = np.mean(accs)\n",
        "    mean_costs = np.mean(costs)\n",
        "    \n",
        "    if mean_accs > history['best_acc']:  \n",
        "        history['best_acc'] = mean_accs\n",
        "        history['best_model'] = copy.deepcopy(model.state_dict())\n",
        "        \n",
        "    history['validate_accuracy'].append(mean_accs)\n",
        "    history['validate_loss'].append(mean_costs)\n",
        "    return mean_costs, mean_accs\n",
        "\n",
        "def train(model, criterion, optimizer, epoch, history, validate_points):\n",
        "    model.train()\n",
        "    costs = []\n",
        "    accs = []\n",
        "    with tqdm(total=len(train_dataset), desc='Epoch {}'.format(epoch)) as pbar:\n",
        "        for idx, batch in enumerate(train_dataloader):\n",
        "            input_batch, labels, lengths = batch\n",
        "            labels = labels.float().unsqueeze(1) # polarity\n",
        "           \n",
        "            # output = model(input_batch, lengths) # RNN\n",
        "            output = model(input_batch)  # Transformer\n",
        "\n",
        "            loss = criterion(output, labels) \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                costs.append(loss.item())\n",
        "                # polarity\n",
        "                accs.append((output>0).eq(labels>0).float().mean().item())\n",
        "                pbar.update(input_batch.size(0))\n",
        "                pbar.set_postfix_str('train-loss: {:.4f}, train-acc: {:.4f}'.format(np.mean(costs), np.mean(accs)))\n",
        "\n",
        "            if idx in validate_points:\n",
        "                val_loss, val_acc = validate(model, criterion, history)\n",
        "                pbar.set_postfix_str('train-loss: {:.4f}, train-acc: {:.4f}, val-loss: {:.4f}, val-acc: {:.4f}'.format(np.mean(costs), np.mean(accs), val_loss, val_acc))\n",
        "                model.train()\n",
        "            torch.cuda.empty_cache()\n",
        "    \n",
        "    history['train_loss'].append(costs)\n",
        "    history['train_accuracy'].append(accs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqlAaVYFnLAr"
      },
      "source": [
        "history = { 'best_acc': 0,\n",
        "            'best_model': None,\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'train_accuracy': [],\n",
        "            'train_loss': [],\n",
        "            'validate_accuracy': [],\n",
        "            'validate_loss': [],\n",
        "            'batch_size': BATCH_SIZE,\n",
        "            'num_of_batch': len(train_dataloader),\n",
        "            'train_size': len(train_dataset),\n",
        "            'validate_size': len(val_dataset),\n",
        "            'validate_points': None,\n",
        "            'epochs': 0,\n",
        "            'embedding_size': embedding_matrix.shape,\n",
        "            'parameters': parameters\n",
        "          }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUjTJhILnNJu"
      },
      "source": [
        "epochs = 2\n",
        "validate_points = list(np.linspace(0, len(train_dataloader)-1, 4).astype(int))[1:]\n",
        "history['epochs'] = epochs\n",
        "history['validate_points'] = validate_points"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVY_t3b3nQU_"
      },
      "source": [
        "# Attention Model on IMDB dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKohbiOTnT0j"
      },
      "source": [
        "### Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjzCNY-onN11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22190bf3-f404-4d1a-9b11-fbedc58a6712"
      },
      "source": [
        "%%time\n",
        "timestamp = time.strftime('%Y-%m-%d-%H-%M',time.localtime(time.time()))\n",
        "for epoch in range(1, epochs+1):\n",
        "    train(model, criterion, optimizer, epoch, history, validate_points)\n",
        "    # torch.save(history, '{}model_save/{}-{}.pth'.format(base_dir, 'Transformer-on-IMDB-l1-h1', timestamp))\n",
        "    torch.save(history, '{}model_save/{}.pth'.format(base_dir, MODEL_NAME))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 447872/447872 [09:43<00:00, 767.87it/s, train-loss: 0.2443, train-acc: 0.8967, val-loss: 0.1799, val-acc: 0.9286] \n",
            "Epoch 2: 100%|██████████| 447872/447872 [09:45<00:00, 765.38it/s, train-loss: 0.1919, train-acc: 0.9232, val-loss: 0.1767, val-acc: 0.9314] \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10min 19s, sys: 8min 55s, total: 19min 14s\n",
            "Wall time: 19min 29s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESzYJy9lofpB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f1ab097-6c62-4fe3-dcfa-6a003a95286d"
      },
      "source": [
        "history['best_acc']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9314375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX-vJhP51kar"
      },
      "source": [
        "# Evaluate and Test model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvG1EpuODCqP",
        "outputId": "5a8265cd-c346-47a3-d4fd-b9d179d64a1a"
      },
      "source": [
        "# X_test = pd.read_hdf('dataset/IMDB/X_test.h5', key='s')\n",
        "# y_test = pd.read_hdf('dataset/IMDB/y_test.h5', key='s')\n",
        "\n",
        "X_test = pd.read_hdf('dataset/Yelp/X_test.h5', key='s')\n",
        "y_test = pd.read_hdf('dataset/Yelp/y_test.h5', key='s')\n",
        "\n",
        "len(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO4q-X11Dmg7"
      },
      "source": [
        "X_test_tensors = [torch.tensor(x, dtype=torch.int64) for x in X_test]\n",
        "y_test_tensors = [torch.tensor(y, dtype=torch.int64) for y in y_test]\n",
        "\n",
        "X_test_tensors = [pad_or_truncate(x, maxlen=MAXLEN, pad=True) for x in X_test_tensors]\n",
        "\n",
        "test_dataset = CustomDataset(X_test_tensors, y_test_tensors)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=pad_and_sort_batch, worker_init_fn=worker_init_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou9G3-Rz1uNa"
      },
      "source": [
        "## Load trained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD8En9Sv11w6"
      },
      "source": [
        "def load_Transformer_model(path, output_size=1):\n",
        "    history = torch.load(path)\n",
        "    parameters = history['parameters']\n",
        "    architecture = (parameters['n_layers'], parameters['d_model'], parameters['d_ff'], parameters['n_heads'], parameters['d_k'], parameters['d_v'])\n",
        "    model = Transformer(output_size=1, architecture=architecture, embedding=parameters['embedding'], method=parameters['final_att_method'], maxpos=MAXLEN, embedding_dropout=parameters['embedding_dropout'], multihead_dropout=parameters['multihead_dropout'], att_dropout=parameters['att_dropout'], feedforward_dropout=parameters['feedforward_dropout'], final_dropout=parameters['final_dropout'])\n",
        "    model.to(DEVICE)\n",
        "    model.load_state_dict(history['best_model'])\n",
        "    return model, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTsmv96r2Hk3"
      },
      "source": [
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "def predict(model, data_loader, criterion, history):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "      for idx, batch in enumerate(data_loader):\n",
        "          input_batch, labels, lengths = batch\n",
        "          labels = labels.float().unsqueeze(1) # polarity\n",
        "          output = model(input_batch)  # Transformer\n",
        "          y_true.append(labels.cpu())\n",
        "          y_pred.append(output.cpu())\n",
        "          torch.cuda.empty_cache()\n",
        "    return torch.cat(y_pred), torch.cat(y_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNqd6esn2KMV"
      },
      "source": [
        "## Loss & Accuracy & Precision & Recall & F1 score & roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZLYehdz2LQ5"
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
        "def evaluate(y_pred, y_true, multiclass=False, model_name='', dataset=''):\n",
        "    if multiclass:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        loss = criterion(y_pred, y_true).item()\n",
        "        _, preds = torch.max(y_pred, 1)\n",
        "        accuracy = (preds == y_true).float().mean().item()\n",
        "        return pd.Series([model_name, dataset, accuracy, loss], index=['model', 'dataset', 'accuracy', 'loss'])\n",
        "    else:\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "        loss = criterion(y_pred, y_true).item()\n",
        "        accuracy = (y_pred>0).eq(y_true>0).float().mean().item()\n",
        "        f1 = f1_score(y_true, y_pred>0)\n",
        "        precision = precision_score(y_true, y_pred>0)\n",
        "        recall = recall_score(y_true, y_pred>0)\n",
        "        auc = roc_auc_score(y_true, y_pred)\n",
        "        return pd.Series([model_name, dataset, accuracy, loss, f1, precision, recall, auc], index=['model', 'dataset', 'accuracy', 'loss', 'f1', 'precision', 'recall', 'auc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CoIZrfg2RCV"
      },
      "source": [
        "## Evaluate all the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG6OuFYj2SG1",
        "outputId": "3b9d8b78-f13d-4cf3-d034-df1505cf0212"
      },
      "source": [
        "evaluate_df = pd.DataFrame()\n",
        "os.listdir('output/model_save/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.ipynb_checkpoints', 'Transformer-on-Yelp-l3-h1.pth']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvgdcmuN2XfC"
      },
      "source": [
        "### Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7q8oZkN2YBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14c84541-7776-4868-f835-82578dc65807"
      },
      "source": [
        "# transformer_on_imdb, transformer_on_imdb_history = load_Transformer_model(base_dir+'model_save/' + MODEL_NAME + '.pth')\n",
        "# transformer_on_imdb.eval()\n",
        "transformer_on_yelp, transformer_on_yelp_history = load_Transformer_model(base_dir+'model_save/' + MODEL_NAME + '.pth')\n",
        "transformer_on_yelp.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (pos_add_word_embedding): PE_add_Embedding(\n",
              "    (word_embedding): Embedding(20000, 200)\n",
              "    (pos_embedding): Embedding(501, 200)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (encode_layers): ModuleList(\n",
              "    (0): EncoderLayer(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (linear_Q): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (linear_K): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (linear_V): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (attn): ScaleDotProductAttention(\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (out_linear): Linear(in_features=60, out_features=200, bias=True)\n",
              "        (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (postion_feedforward): PoswiseFeedForward(\n",
              "        (conv1): Conv1d(200, 512, kernel_size=(1,), stride=(1,))\n",
              "        (conv2): Conv1d(512, 200, kernel_size=(1,), stride=(1,))\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (1): EncoderLayer(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (linear_Q): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (linear_K): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (linear_V): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (attn): ScaleDotProductAttention(\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (out_linear): Linear(in_features=60, out_features=200, bias=True)\n",
              "        (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (postion_feedforward): PoswiseFeedForward(\n",
              "        (conv1): Conv1d(200, 512, kernel_size=(1,), stride=(1,))\n",
              "        (conv2): Conv1d(512, 200, kernel_size=(1,), stride=(1,))\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (2): EncoderLayer(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (linear_Q): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (linear_K): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (linear_V): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (attn): ScaleDotProductAttention(\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (out_linear): Linear(in_features=60, out_features=200, bias=True)\n",
              "        (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (postion_feedforward): PoswiseFeedForward(\n",
              "        (conv1): Conv1d(200, 512, kernel_size=(1,), stride=(1,))\n",
              "        (conv2): Conv1d(512, 200, kernel_size=(1,), stride=(1,))\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inter_attn): InterAttention(\n",
              "    (linear): Linear(in_features=400, out_features=200, bias=True)\n",
              "    (v): Linear(in_features=200, out_features=1, bias=True)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc): Linear(in_features=200, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTtlFY-K8TEr"
      },
      "source": [
        "# y_pred, y_true = predict(transformer_on_imdb, test_dataloader, criterion, history)\n",
        "# evaluate_df = evaluate_df.append(evaluate(y_pred, y_true, model_name=MODEL_NAME, dataset='IMDB'), ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCO1SvWWrwAu"
      },
      "source": [
        "y_pred, y_true = predict(transformer_on_yelp, test_dataloader, criterion, history)\n",
        "y_pred[torch.isnan(y_pred)] = 0\n",
        "evaluate_df = evaluate_df.append(evaluate(y_pred, y_true, model_name=MODEL_NAME, dataset='Yelp'), ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AFp4R_R2dF_"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "cOQAlLWQ2h4T",
        "outputId": "6eca553e-482b-43a9-efcf-31521c86c059"
      },
      "source": [
        "evaluate_df.to_csv('evaluate_df.csv', index=False)\n",
        "evaluate_df.sort_values(by='dataset').set_index(['dataset', 'model'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>auc</th>\n",
              "      <th>f1</th>\n",
              "      <th>loss</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dataset</th>\n",
              "      <th>model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Yelp</th>\n",
              "      <th>Transformer-on-Yelp-l3-h1</th>\n",
              "      <td>0.931761</td>\n",
              "      <td>0.981679</td>\n",
              "      <td>0.931998</td>\n",
              "      <td>0.174705</td>\n",
              "      <td>0.928758</td>\n",
              "      <td>0.93526</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   accuracy       auc  ...  precision   recall\n",
              "dataset model                                          ...                    \n",
              "Yelp    Transformer-on-Yelp-l3-h1  0.931761  0.981679  ...   0.928758  0.93526\n",
              "\n",
              "[1 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVvyo49m2j5I"
      },
      "source": [
        "df = evaluate_df.set_index('model')\n",
        "df.index = df.index.str.extract('(.*)-on')[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "uW9qsDX22pHA",
        "outputId": "0c6b4883-1913-422e-f306-786c10ffaee8"
      },
      "source": [
        "# imdb_accuracy = df[df['dataset']=='IMDB']['accuracy']\n",
        "# accuracy_df = pd.concat([imdb_accuracy], axis=1)\n",
        "\n",
        "yelp_accuracy = df[df['dataset']=='Yelp']['accuracy']\n",
        "accuracy_df = pd.concat([yelp_accuracy], axis=1)\n",
        "\n",
        "accuracy_df.columns = [MODEL_NAME + '-Accuracy']\n",
        "accuracy_df.index.name=None\n",
        "accuracy_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Transformer-on-Yelp-l3-h1-Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Transformer</th>\n",
              "      <td>0.931761</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Transformer-on-Yelp-l3-h1-Accuracy\n",
              "Transformer                            0.931761"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "Kano1lIu2vS8",
        "outputId": "7183b0cc-f5d9-4e1a-975e-c7eba6df7094"
      },
      "source": [
        "# imdb_loss = df[df['dataset']=='IMDB']['loss']\n",
        "# loss_df = pd.concat([imdb_loss], axis=1)\n",
        "\n",
        "yelp_loss = df[df['dataset']=='Yelp']['loss']\n",
        "loss_df = pd.concat([yelp_loss], axis=1)\n",
        "\n",
        "loss_df.columns = [MODEL_NAME + '-Loss']\n",
        "loss_df.index.name=None\n",
        "loss_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Transformer-on-Yelp-l3-h1-Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Transformer</th>\n",
              "      <td>0.174705</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Transformer-on-Yelp-l3-h1-Loss\n",
              "Transformer                        0.174705"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPvw4Aky2xWq"
      },
      "source": [
        "# ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "vMTBzUgU2yNC",
        "outputId": "fc4bfc6f-a9ff-4a3b-9941-643f2d41478c"
      },
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
        "score = roc_auc_score(y_true, y_pred)\n",
        "\n",
        "plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
        "plt.xlabel(\"FPR\")\n",
        "plt.ylabel(\"TPR (recall)\")\n",
        "plt.title('ROC Curve (AUC = {:.4f})'.format(score))\n",
        "plt.legend(loc=4)\n",
        "ROC_name = MODEL_NAME + '_ROC.png'\n",
        "plt.savefig(ROC_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iZKOfCkBrq5"
      },
      "source": [
        "# Attention Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyHq6n8SBxxI"
      },
      "source": [
        "## Load trained models and parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdWWQ4C-9AcK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db6cbf6a-32a1-44ff-c7bb-bc7c0da1d578"
      },
      "source": [
        "# transformer_on_imdb, transformer_on_imdb_history = load_Transformer_model(base_dir+'model_save/' + MODEL_NAME + '.pth')\n",
        "# transformer_on_imdb.eval()\n",
        "\n",
        "transformer_on_yelp, transformer_on_yelp_history = load_Transformer_model(base_dir+'model_save/' + MODEL_NAME + '.pth')\n",
        "transformer_on_yelp.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (pos_add_word_embedding): PE_add_Embedding(\n",
              "    (word_embedding): Embedding(20000, 200)\n",
              "    (pos_embedding): Embedding(501, 200)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (encode_layers): ModuleList(\n",
              "    (0): EncoderLayer(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (linear_Q): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (linear_K): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (linear_V): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (attn): ScaleDotProductAttention(\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (out_linear): Linear(in_features=60, out_features=200, bias=True)\n",
              "        (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (postion_feedforward): PoswiseFeedForward(\n",
              "        (conv1): Conv1d(200, 512, kernel_size=(1,), stride=(1,))\n",
              "        (conv2): Conv1d(512, 200, kernel_size=(1,), stride=(1,))\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (1): EncoderLayer(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (linear_Q): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (linear_K): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (linear_V): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (attn): ScaleDotProductAttention(\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (out_linear): Linear(in_features=60, out_features=200, bias=True)\n",
              "        (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (postion_feedforward): PoswiseFeedForward(\n",
              "        (conv1): Conv1d(200, 512, kernel_size=(1,), stride=(1,))\n",
              "        (conv2): Conv1d(512, 200, kernel_size=(1,), stride=(1,))\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (2): EncoderLayer(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (linear_Q): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (linear_K): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (linear_V): Linear(in_features=200, out_features=60, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (attn): ScaleDotProductAttention(\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (out_linear): Linear(in_features=60, out_features=200, bias=True)\n",
              "        (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (postion_feedforward): PoswiseFeedForward(\n",
              "        (conv1): Conv1d(200, 512, kernel_size=(1,), stride=(1,))\n",
              "        (conv2): Conv1d(512, 200, kernel_size=(1,), stride=(1,))\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inter_attn): InterAttention(\n",
              "    (linear): Linear(in_features=400, out_features=200, bias=True)\n",
              "    (v): Linear(in_features=200, out_features=1, bias=True)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc): Linear(in_features=200, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4vTjNWbDO_V"
      },
      "source": [
        "## Get the attention layer output by Pytorch hook function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsEaRk4_DMmM"
      },
      "source": [
        "att_weights = []\n",
        "def hook_attention(module, input, output):\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        global att_weights\n",
        "        att_weights.clear()\n",
        "\n",
        "        att_weights.append(output[0].data.cpu().numpy())\n",
        "        # att_weights.append(output.data.cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOC-Bn_hDWGE"
      },
      "source": [
        "try:\n",
        "    handle.remove()\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# handle = transformer_on_imdb.inter_attn.register_forward_hook(hook_attention)\n",
        "handle = transformer_on_yelp.inter_attn.register_forward_hook(hook_attention)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcCJPmKPDaGj"
      },
      "source": [
        "## Load data for visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwwr4jTJDZnh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a3174a4e-5862-441e-c84f-6293d9dd0bdf"
      },
      "source": [
        "# df_test = pd.read_csv('dataset/IMDB/test.csv')\n",
        "df_test = pd.read_csv('dataset/Yelp/yelp_test.csv')\n",
        "df_test.columns = ['label', 'review']\n",
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Last summer I had an appointment to get new ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Friendly staff, same starbucks fair you get an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>The food is good. Unfortunately the service is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>Even when we didn't have a car Filene's Baseme...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>Picture Billy Joel's \\\"Piano Man\\\" DOUBLED mix...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                             review\n",
              "0      1  Last summer I had an appointment to get new ti...\n",
              "1      2  Friendly staff, same starbucks fair you get an...\n",
              "2      1  The food is good. Unfortunately the service is...\n",
              "3      2  Even when we didn't have a car Filene's Baseme...\n",
              "4      2  Picture Billy Joel's \\\"Piano Man\\\" DOUBLED mix..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXVL7oafFJPH"
      },
      "source": [
        "## Predict single example and visualize attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA3AtvtjFKo7"
      },
      "source": [
        "def predict_single_example(model, text, zh=False):\n",
        "    if zh:\n",
        "        df_words = pd.DataFrame(list(jieba.cut(text)), columns=['raw_word'])\n",
        "        df_words['clean_word'] = df_words['raw_word']\n",
        "    else:\n",
        "        df_words = pd.DataFrame(transform_punc(text).split(), columns=['raw_word'])\n",
        "        df_words['clean_word'] = df_words['raw_word'].apply(clean_text).str.replace(r'\\s+', '')\n",
        "\n",
        "    df_words['word_id'] = df_words['clean_word'].apply(lambda x: word2num_series.get(x, None))\n",
        "    num_series = df_words['word_id'].dropna().astype(int)\n",
        "    X = torch.tensor(list(num_series), dtype=torch.int64).to(DEVICE).unsqueeze(0)\n",
        "    length = torch.tensor([len(num_series)]).to(DEVICE)\n",
        "    \n",
        "    model.eval()\n",
        "    predict = model(X)\n",
        "    wts = att_weights[0]\n",
        "    if wts.shape[1] < len(num_series):\n",
        "      diff = len(num_series) - wts.shape[1]\n",
        "      z = np.zeros(diff)\n",
        "      wts_ = np.concatenate((wts, z), axis=None)\n",
        "      wts_ = wts_.reshape((1, wts_.shape[0]))\n",
        "    \n",
        "    else:\n",
        "      wts_ = wts[:, :len(num_series)]\n",
        "    att_series = pd.Series(wts_.squeeze(0), index=num_series.index)\n",
        "    \n",
        "    df_words['att_weights'] = att_series\n",
        "    df_words.fillna(0, inplace=True)\n",
        "    return F.sigmoid(predict).item(), df_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3eEj4F0FWa-"
      },
      "source": [
        "# Examples in IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-96jIu4FZH5"
      },
      "source": [
        "index = 1023\n",
        "\n",
        "# predict, attention_df = predict_single_example(transformer_on_imdb, df_test['review'][index], zh=False)\n",
        "predict, attention_df = predict_single_example(transformer_on_yelp, df_test['review'][index], zh=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNGq5hYtdiKP"
      },
      "source": [
        "import matplotlib\n",
        "def colorize(words, color_array):\n",
        "    cmap=matplotlib.cm.Blues\n",
        "    template = '<span class=\"barcode\"; style=\"color: black; background-color: {}\">{}</span>'\n",
        "    colored_string = ''\n",
        "    for word, color in zip(words, color_array):\n",
        "        color = matplotlib.colors.rgb2hex(cmap(color)[:3])\n",
        "        # print(color)\n",
        "        colored_string += template.format(color, '&nbsp' + word + '&nbsp')\n",
        "    return colored_string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw6Jr-CIdkAU"
      },
      "source": [
        "html_filename = MODEL_NAME + '.html'\n",
        "attention_map = colorize(attention_df['raw_word'], attention_df['att_weights'])\n",
        "with open(html_filename, 'w') as f:\n",
        "    f.write(attention_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ds4_M4Nd8bM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}